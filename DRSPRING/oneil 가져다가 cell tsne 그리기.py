oneil 가져다가 cell tsne 그리기 

# cell filter 된 oneil 
get /home01/k040a01/ray_results/PRJ02.23.07.10.M3V6.WORK_214_1.349.MIS2/RAY_MY_train_70f0b_00000_0_CV=0,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-10_15-24-36/checkpoint_000999/checkpoint CV_0
get /home01/k040a01/ray_results/PRJ02.23.07.10.M3V6.WORK_214_1.349.MIS2/RAY_MY_train_70f0b_00001_1_CV=1,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-10_15-24-39/checkpoint_000999/checkpoint CV_1
get /home01/k040a01/ray_results/PRJ02.23.07.10.M3V6.WORK_214_1.349.MIS2/RAY_MY_train_70f0b_00002_2_CV=2,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-10_15-24-39/checkpoint_000999/checkpoint CV_2
get /home01/k040a01/ray_results/PRJ02.23.07.10.M3V6.WORK_214_1.349.MIS2/RAY_MY_train_70f0b_00003_3_CV=3,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-10_15-24-39/checkpoint_000999/checkpoint CV_3
get /home01/k040a01/ray_results/PRJ02.23.07.10.M3V6.WORK_214_1.349.MIS2/RAY_MY_train_70f0b_00004_4_CV=4,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-10_15-24-39/checkpoint_000999/checkpoint CV_4


# cell filter 안된 full oneil 217_1
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_1.349.MIS2/RAY_MY_train_8c8ef_00000_0_CV=0,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_11-17-20/checkpoint_000999/checkpoint CV_0
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_1.349.MIS2/RAY_MY_train_8c8ef_00001_1_CV=1,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_11-17-23/checkpoint_000999/checkpoint CV_1
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_1.349.MIS2/RAY_MY_train_8c8ef_00002_2_CV=2,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_11-17-23/checkpoint_000999/checkpoint CV_2
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_1.349.MIS2/RAY_MY_train_8c8ef_00003_3_CV=3,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_11-17-23/checkpoint_000999/checkpoint CV_3
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_1.349.MIS2/RAY_MY_train_8c8ef_00004_4_CV=4,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_11-17-23/checkpoint_000999/checkpoint CV_4

# cell filter 안됐지만 target filter 는 된 full oneil 217_2
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_2.349.MIS2/RAY_MY_train_7e712_00000_0_CV=0,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_12-21-22/checkpoint_000999/checkpoint CV_0
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_2.349.MIS2/RAY_MY_train_7e712_00000_0_CV=0,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_12-21-22/checkpoint_000999/checkpoint CV_1
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_2.349.MIS2/RAY_MY_train_7e712_00000_0_CV=0,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_12-21-22/checkpoint_000999/checkpoint CV_2
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_2.349.MIS2/RAY_MY_train_7e712_00000_0_CV=0,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_12-21-22/checkpoint_000999/checkpoint CV_3
get /home01/k040a01/ray_results/PRJ02.23.07.26.M3V6.WORK_217_2.349.MIS2/RAY_MY_train_7e712_00000_0_CV=0,G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout__2023-07-26_12-21-22/checkpoint_000999/checkpoint CV_4


NETWORK_PATH = '/st06/jiyeonH/13.DD_SESS/HumanNetV3/'
LINCS_PATH = '/st06/jiyeonH/11.TOX/MY_TRIAL_5/' 
DATA_PATH = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V3_FULL/'
DC_PATH = '/st06/jiyeonH/11.TOX/DR_SPRING/'



# HS Drug pathway DB 활용 -> 349
print('NETWORK')
# HUMANNET 사용 

hunet_gsp = pd.read_csv(NETWORK_PATH+'HS-DB.tsv', sep = '\t', header = None)
hunet_gsp.columns = ['G_A','G_B','SC']

LINCS_gene_file = pd.read_csv(LINCS_PATH+'geneinfo_beta.txt', sep = '\t')
LINCS_978 = LINCS_gene_file[LINCS_gene_file.feature_space == 'landmark']
LINCS_978 = LINCS_978[['gene_id','gene_symbol']]
LINCS_978['new_node'] = [str(list(LINCS_978.gene_id)[i]) + "__" + list(LINCS_978.gene_symbol)[i] for i in range(978)]
LINCS_978 = LINCS_978.reset_index(drop=True)
lm_entrezs = list(LINCS_978.gene_id)

hnet_L1 = hunet_gsp[hunet_gsp['G_A'].isin(lm_entrezs)]
hnet_L2 = hnet_L1[hnet_L1['G_B'].isin(lm_entrezs)] # 3885
hnet_L3 = hnet_L2[hnet_L2.SC >= 3.5]

len(set(list(hnet_L3['G_A']) + list(hnet_L3['G_B']))) # 611

ID_G = nx.from_pandas_edgelist(hnet_L3, 'G_A', 'G_B')

# MSSNG = [a for a in lm_entrezs if a not in list(ID_G.nodes)]

#for nn in list(MSSNG):
#       ID_G.add_node(nn)

# edge 
ID_GENE_ORDER_mini = list(ID_G.nodes()) # 978
ID_ADJ = nx.adjacency_matrix(ID_G)
ID_ADJ_tmp = torch.LongTensor(ID_ADJ.toarray())
ID_ADJ_IDX = ID_ADJ_tmp.to_sparse().indices()  # [2, 7742]
ID_WEIGHT = [] # len : 3871 -> 7742

# 원래는 edge score 있지만 일단은...
ID_WEIGHT_SCORE = [1 for a in range(ID_ADJ_IDX.shape[1])]



# 유전자 이름으로 붙이기 

new_node_names = []
for a in ID_G.nodes():
        tmp_name = LINCS_978[LINCS_978.gene_id == a ]['gene_symbol'].item() # 6118
        new_node_name = str(a) + '__' + tmp_name
        new_node_names = new_node_names + [new_node_name]

mapping = {list(ID_G.nodes())[a]:new_node_names[a] for a in range(len(new_node_names))}

ID_G_RE = nx.relabel_nodes(ID_G, mapping)

MY_G = ID_G_RE
MY_WEIGHT_SCORE = ID_WEIGHT_SCORE # SCORE





# Graph 확인 

JY_GRAPH = MY_G
JY_GRAPH_ORDER = MY_G.nodes()
JY_ADJ = nx.adjacency_matrix(JY_GRAPH)

JY_ADJ_tmp = torch.LongTensor(JY_ADJ.toarray())
JY_ADJ_IDX = JY_ADJ_tmp.to_sparse().indices()
JY_IDX_WEIGHT = MY_WEIGHT_SCORE



# LINCS exp order 따지기 
BETA_ORDER_pre = [list(LINCS_978.new_node).index(a) for a in JY_GRAPH_ORDER]
BETA_ORDER_DF = LINCS_978.iloc[BETA_ORDER_pre] # 어차피 ref 다르고 같은 애들이라 괜춘 
BETA_ENTREZ_ORDER = list(BETA_ORDER_DF.gene_id)
BETA_SYMBOL_ORDER = list(BETA_ORDER_DF.gene_symbol)
BETA_NEWNOD_ORDER = list(BETA_ORDER_DF.new_node)




SAVE_PATH = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_349_FULL/'

file_name = 'M3V6_349_MISS2_ONEIL'

A_B_C_S_SET_ADD = pd.read_csv(SAVE_PATH+'{}.A_B_C_S_SET_ADD.csv'.format(file_name), low_memory=False)
MY_chem_A_feat = torch.load(SAVE_PATH+'{}.MY_chem_A_feat.pt'.format(file_name))
MY_chem_B_feat = torch.load(SAVE_PATH+'{}.MY_chem_B_feat.pt'.format(file_name))
MY_chem_A_adj = torch.load(SAVE_PATH+'{}.MY_chem_A_adj.pt'.format(file_name))
MY_chem_B_adj = torch.load(SAVE_PATH+'{}.MY_chem_B_adj.pt'.format(file_name))
MY_g_EXP_A = torch.load(SAVE_PATH+'{}.MY_g_EXP_A.pt'.format(file_name))
MY_g_EXP_B = torch.load(SAVE_PATH+'{}.MY_g_EXP_B.pt'.format(file_name))
MY_Target_1_A = torch.load(SAVE_PATH+'{}.MY_Target_1_A.pt'.format(file_name))
MY_Target_1_B = torch.load(SAVE_PATH+'{}.MY_Target_1_B.pt'.format(file_name))
MY_CellBase = torch.load(SAVE_PATH+'{}.MY_CellBase.pt'.format(file_name))
MY_syn = torch.load(SAVE_PATH+'{}.MY_syn.pt'.format(file_name))



A_B_C_S_SET_ADD2 = copy.deepcopy(A_B_C_S_SET_ADD)

cid_a = list(A_B_C_S_SET_ADD2['CID_A'])
cid_b = list(A_B_C_S_SET_ADD2['CID_B'])
sm_a = list(A_B_C_S_SET_ADD2['ROW_CAN_SMILES'])
sm_b = list(A_B_C_S_SET_ADD2['COL_CAN_SMILES'])
ccle = list(A_B_C_S_SET_ADD2['CELL'])



A_B_C_S_SET_ADD2['CID_CID'] = [str(int(cid_a[i])) + '___' + str(int(cid_b[i])) if cid_a[i] < cid_b[i] else str(int(cid_b[i])) + '___' + str(int(cid_a[i])) for i in range(A_B_C_S_SET_ADD2.shape[0])]
A_B_C_S_SET_ADD2['SM_C_CHECK'] = [sm_a[i] + '___' + sm_b[i]+ '___' + ccle[i] if sm_a[i] < sm_b[i] else sm_b[i] + '___' + sm_a[i]+ '___' + ccle[i] for i in range(A_B_C_S_SET_ADD2.shape[0])]

A_B_C_S_SET_ADD2['ori_index'] = list(A_B_C_S_SET_ADD2.index)




MISS_filter = ['AOBO','AXBX','AXBO','AOBX'] # 

A_B_C_S_SET = A_B_C_S_SET_ADD2[A_B_C_S_SET_ADD2.Basal_Exp == 'O']

A_B_C_S_SET = A_B_C_S_SET[A_B_C_S_SET.ONEIL == 'O'] # 16422

# A_B_C_S_SET = A_B_C_S_SET[A_B_C_S_SET.SYN_OX == 'O'] # 11639

#A_B_C_S_SET = A_B_C_S_SET[A_B_C_S_SET.T1OX == 'O'] # 8086 -> 이걸 빼야하나 말아야하나 

A_B_C_S_SET = A_B_C_S_SET[A_B_C_S_SET.type.isin(MISS_filter)]




# basal node exclude -> CCLE match 만 사용
CCLE_PATH = '/st06/jiyeonH/13.DD_SESS/CCLE.22Q1/'
ccle_exp = pd.read_csv(CCLE_PATH+'CCLE_expression.csv', low_memory=False)
ccle_info= pd.read_csv(CCLE_PATH+'sample_info.csv', low_memory=False)

ccle_cell_info = ccle_info[['DepMap_ID','CCLE_Name']]
ccle_cell_info.columns = ['DepMap_ID','DrugCombCCLE']

ccle_cell_info_filt = ccle_cell_info[ccle_cell_info.DepMap_ID.isin(ccle_exp['Unnamed: 0'])]
ccle_names = [a for a in ccle_cell_info_filt.DrugCombCCLE if type(a) == str]


A_B_C_S_SET = A_B_C_S_SET[A_B_C_S_SET.CELL.isin(ccle_names)]




data_ind = list(A_B_C_S_SET.index)

MY_chem_A_feat_RE = MY_chem_A_feat[data_ind]
MY_chem_B_feat_RE = MY_chem_B_feat[data_ind]
MY_chem_A_adj_RE = MY_chem_A_adj[data_ind]
MY_chem_B_adj_RE = MY_chem_B_adj[data_ind]
MY_g_EXP_A_RE = MY_g_EXP_A[data_ind]
MY_g_EXP_B_RE = MY_g_EXP_B[data_ind]
MY_Target_A = copy.deepcopy(MY_Target_1_A)[data_ind] ############## NEW TARGET !!!!!! #####
MY_Target_B = copy.deepcopy(MY_Target_1_B)[data_ind] ############## NEW TARGET !!!!!! #####
MY_CellBase_RE = MY_CellBase[data_ind]
MY_syn_RE = MY_syn[data_ind]


A_B_C_S_SET = A_B_C_S_SET.reset_index(drop = True)





# cell line vector 

DC_CELL_DF2 = pd.read_csv(DC_PATH+'DC_CELL_INFO.csv', sep = '\t')
DC_CELL_DF2 = pd.concat([
        DC_CELL_DF2,
        pd.DataFrame({'cell_line_id' : [1],'DC_cellname' : ['786O'],'DrugCombCello' : ['CVCL_1051'],'DrugCombCCLE':['786O_KIDNEY']})])

DC_CELL_info_filt = DC_CELL_DF2[DC_CELL_DF2.DrugCombCCLE.isin(A_B_C_S_SET.CELL)] # 38

DC_CELL_info_filt = DC_CELL_info_filt.drop(['Unnamed: 0'], axis = 1)
DC_CELL_info_filt.columns = ['cell_line_id', 'DC_cellname', 'DrugCombCello', 'CELL']
DC_CELL_info_filt = DC_CELL_info_filt[['CELL','DC_cellname']]

A_B_C_S_SET_COH = pd.merge(A_B_C_S_SET, DC_CELL_info_filt, on = 'CELL', how = 'left'  )





# sample number filter 

# 빈도 확인 

C_names = list(set(A_B_C_S_SET_COH.DC_cellname))
C_names.sort()

C_freq = [list(A_B_C_S_SET_COH.DC_cellname).count(a) for a in C_names]
C_cclename = [list(A_B_C_S_SET_COH[A_B_C_S_SET_COH.DC_cellname==a]['CELL'])[0] for a in C_names]

C_df = pd.DataFrame({'cell' : C_names, 'freq' : C_freq, 'ccle' : C_cclename})
C_df = C_df.sort_values('freq')



CELL_CUT = 200
C_freq_filter = C_df[C_df.freq > CELL_CUT ] 

# C_freq_filter = C_df



A_B_C_S_SET_COH = A_B_C_S_SET_COH[A_B_C_S_SET_COH.DC_cellname.isin(C_freq_filter.cell)]

DC_CELL_info_filt_re = DC_CELL_info_filt[DC_CELL_info_filt.DC_cellname.isin(C_freq_filter.cell)]
DC_CELL_info_filt_re['cell_onehot'] = [a for a in range(len(set(DC_CELL_info_filt_re.CELL)))]

DC_CELL_info_filt_re = DC_CELL_info_filt_re.reset_index(drop = True)


#no_TF_CID = [104842, 208908, 46926350, 24964624, 5394, 11977753, 60700, 15953832, 3062316, 24748204, 216239, 3385, 5288382, 5311, 59691338, 60750, 5329102, 11960529, 31703, 2907, 126941, 9826528, 176870, 36462, 5743, 5746, 24856436, 387447, 24958200, 4091]
#no_TF_CELL = ['T-47D', 'RKO', 'ES2', 'RPMI7951', 'NCIH520', 'MSTO', 'NCIH2122', 'MDAMB436', 'OV90', 'KPL1', 'HT144', 'A375', 'PA1', 'CAOV3', 'OVCAR3', 'LOVO', 'NCIH1650', 'A427', 'VCAP', 'NCI-H460', 'SK-OV-3', 'DLD1', 'A2058', 'SW837', 'SKMES1', 'UWB1289', 'HCT116', 'A2780', 'ZR751', 'UACC62', 'SW-620', 'NCIH23', 'SKMEL30', 'HT29']



#ON_filt_1 = A_B_C_S_SET_COH[A_B_C_S_SET_COH.CID_A.isin(no_TF_CID)]
#ON_filt_2 = ON_filt_1[ON_filt_1.CID_B.isin(no_TF_CID)]
#ON_filt_3 = ON_filt_2[ON_filt_2.DC_cellname.isin(no_TF_CELL)]
#A_B_C_S_SET_COH = copy.deepcopy(ON_filt_3)



data_ind = list(A_B_C_S_SET_COH.index)

MY_chem_A_feat_RE2 = MY_chem_A_feat_RE[data_ind]
MY_chem_B_feat_RE2 = MY_chem_B_feat_RE[data_ind]
MY_chem_A_adj_RE2 = MY_chem_A_adj_RE[data_ind]
MY_chem_B_adj_RE2 = MY_chem_B_adj_RE[data_ind]
MY_g_EXP_A_RE2 = MY_g_EXP_A_RE[data_ind]
MY_g_EXP_B_RE2 = MY_g_EXP_B_RE[data_ind]
MY_Target_A2 = copy.deepcopy(MY_Target_A)[data_ind]
MY_Target_B2 = copy.deepcopy(MY_Target_B)[data_ind]
MY_CellBase_RE2 = MY_CellBase_RE[data_ind]
MY_syn_RE2 = MY_syn_RE[data_ind]

# merge 전 후로 index 달라지므로 뒤에 넣어줬음 
A_B_C_S_SET_COH2 = pd.merge(A_B_C_S_SET_COH, DC_CELL_info_filt_re[['DC_cellname','cell_onehot']], on = 'DC_cellname', how='left')
cell_one_hot = torch.nn.functional.one_hot(torch.Tensor(A_B_C_S_SET_COH2['cell_onehot']).long())



       
print('CIDs', flush = True)
tmp = list(set(A_B_C_S_SET_COH2.CID_CID))
tmp2 = sum([a.split('___') for a in tmp],[])
print(len(set(tmp2)) , flush = True)


print('CID_CID', flush = True)
print(len(set(A_B_C_S_SET_COH2.CID_CID)), flush = True)



print('CID_CID_CCLE', flush = True)
print(len(set(A_B_C_S_SET_COH2.cid_cid_cell)), flush = True)

print('DrugCombCCLE', flush = True)
print(len(set(A_B_C_S_SET_COH2.CELL)), flush = True)


                                             
print("LEARNING")

A_B_C_S_SET_SM = copy.deepcopy(A_B_C_S_SET_COH2) # 

# get unique values, remove duplicates, but keep original counts
data_no_dup, counts = np.unique(list(A_B_C_S_SET_SM['SM_C_CHECK']), return_counts=True)
data_no_dup_cells = [setset.split('___')[2] for setset in data_no_dup]
data_no_dup_sm_sm = [setset.split('___')[0]+'___'+setset.split('___')[1] for setset in data_no_dup]
data_nodup_df = pd.DataFrame({
        'setset' : data_no_dup.tolist(),
        'cell' : data_no_dup_cells,
        'SM_SM' : data_no_dup_sm_sm
         })



SM_SM_list = list(set(data_nodup_df.SM_SM))
SM_SM_list.sort()
sm_sm_list_1 = sklearn.utils.shuffle(SM_SM_list, random_state=42)

bins = [a for a in range(0, len(sm_sm_list_1), round(len(sm_sm_list_1)*0.2) )]
bins = bins[1:]
res = np.split(sm_sm_list_1, bins)

CV_1_smsm = list(res[0])
CV_2_smsm = list(res[1])
CV_3_smsm = list(res[2])
CV_4_smsm = list(res[3])
CV_5_smsm = list(res[4])
if len(res) > 5 :
        CV_5_smsm = list(res[4]) + list(res[5])

len(sm_sm_list_1)
len(CV_1_smsm) + len(CV_2_smsm) + len(CV_3_smsm) + len(CV_4_smsm) + len(CV_5_smsm)

CV_1_setset = list(data_nodup_df[data_nodup_df.SM_SM.isin(CV_1_smsm)]['setset'])
CV_2_setset = list(data_nodup_df[data_nodup_df.SM_SM.isin(CV_2_smsm)]['setset'])
CV_3_setset = list(data_nodup_df[data_nodup_df.SM_SM.isin(CV_3_smsm)]['setset'])
CV_4_setset = list(data_nodup_df[data_nodup_df.SM_SM.isin(CV_4_smsm)]['setset'])
CV_5_setset = list(data_nodup_df[data_nodup_df.SM_SM.isin(CV_5_smsm)]['setset'])




CV_ND_INDS = {
        'CV0_train' : CV_1_setset + CV_2_setset + CV_3_setset + CV_4_setset,
        'CV0_test' : CV_5_setset,
        'CV1_train' : CV_2_setset + CV_3_setset + CV_4_setset + CV_5_setset,
        'CV1_test' : CV_1_setset,
        'CV2_train' : CV_3_setset + CV_4_setset + CV_5_setset + CV_1_setset,
        'CV2_test' : CV_2_setset,
        'CV3_train' : CV_4_setset + CV_5_setset + CV_1_setset + CV_2_setset,
        'CV3_test' : CV_3_setset,
        'CV4_train' : CV_5_setset + CV_1_setset + CV_2_setset + CV_3_setset,
        'CV4_test' : CV_4_setset
}

print(data_nodup_df.shape)
len( CV_1_setset + CV_2_setset + CV_3_setset + CV_4_setset + CV_5_setset)
len(set( CV_1_setset + CV_2_setset + CV_3_setset + CV_4_setset + CV_5_setset ))



with open('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/CV_SM_list.WORK_217_1.pickle', 'rb') as f:
    list_217_1 = pickle.load(f)

CV_ND_INDS == list_217_1

with open('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/CV_SM_list.WORK_217_2.pickle', 'rb') as f:
    list_217_2 = pickle.load(f)

CV_ND_INDS == list_217_2



# 주어진 환경 맞춰서 5CV만 돌릴거라서 수정버전 
def prepare_data_GCN(CV_num, A_B_C_S_SET_SM, MY_chem_A_feat_RE2, MY_chem_B_feat_RE2, MY_chem_A_adj_RE2, MY_chem_B_adj_RE2,
MY_g_EXP_A_RE2, MY_g_EXP_B_RE2, MY_Target_A2, MY_Target_B2, MY_CellBase_RE2,
cell_one_hot, MY_syn_RE2, norm ) :
        # 
        # CV_num = 0
        train_key = 'CV{}_train'.format(CV_num)
        test_key = 'CV{}_test'.format(CV_num)
        # 
        #
        ABCS_tv = A_B_C_S_SET_SM[A_B_C_S_SET_SM.SM_C_CHECK.isin(CV_ND_INDS[train_key])]
        ABCS_test = A_B_C_S_SET_SM[A_B_C_S_SET_SM.SM_C_CHECK.isin(CV_ND_INDS[test_key])]
        #
        #train_ind = list(ABCS_train.index)
        #val_ind = list(ABCS_val.index)
        tv_ind = list(ABCS_tv.index)
        random.shuffle(tv_ind)
        test_ind = list(ABCS_test.index)
        # 
        chem_feat_A_tv = MY_chem_A_feat_RE2[tv_ind]; chem_feat_A_test = MY_chem_A_feat_RE2[test_ind]
        chem_feat_B_tv = MY_chem_B_feat_RE2[tv_ind]; chem_feat_B_test = MY_chem_B_feat_RE2[test_ind]
        chem_adj_A_tv = MY_chem_A_adj_RE2[tv_ind]; chem_adj_A_test = MY_chem_A_adj_RE2[test_ind]
        chem_adj_B_tv = MY_chem_B_adj_RE2[tv_ind]; chem_adj_B_test = MY_chem_B_adj_RE2[test_ind]
        gene_A_tv = MY_g_EXP_A_RE2[tv_ind];  gene_A_test = MY_g_EXP_A_RE2[test_ind]
        gene_B_tv = MY_g_EXP_B_RE2[tv_ind];  gene_B_test = MY_g_EXP_B_RE2[test_ind]
        target_A_tv = MY_Target_A2[tv_ind];  target_A_test = MY_Target_A2[test_ind]
        target_B_tv = MY_Target_B2[tv_ind];  target_B_test = MY_Target_B2[test_ind]
        cell_basal_tv = MY_CellBase_RE2[tv_ind];  cell_basal_test = MY_CellBase_RE2[test_ind]
        cell_tv = cell_one_hot[tv_ind];  cell_test = cell_one_hot[test_ind]
        syn_tv = MY_syn_RE2[tv_ind];  syn_test = MY_syn_RE2[test_ind]
        #
        #
        tv_data = {}
        test_data = {}
        #
        tv_data['drug1_feat'] = torch.concat([chem_feat_A_tv, chem_feat_B_tv], axis = 0)
        test_data['drug1_feat'] = chem_feat_A_test
        #
        tv_data['drug2_feat'] = torch.concat([chem_feat_B_tv, chem_feat_A_tv], axis = 0)
        test_data['drug2_feat'] = chem_feat_B_test
        #
        tv_data['drug1_adj'] = torch.concat([chem_adj_A_tv, chem_adj_B_tv], axis = 0)
        test_data['drug1_adj'] = chem_adj_A_test
        #
        tv_data['drug2_adj'] = torch.concat([chem_adj_B_tv, chem_adj_A_tv], axis = 0)
        test_data['drug2_adj'] = chem_adj_B_test
        #
        tv_data['GENE_A'] = torch.concat([gene_A_tv, gene_B_tv], axis = 0)
        test_data['GENE_A'] = gene_A_test
        #
        tv_data['GENE_B'] = torch.concat([gene_B_tv, gene_A_tv], axis = 0)
        test_data['GENE_B'] = gene_B_test
        #
        tv_data['TARGET_A'] = torch.concat([target_A_tv, target_B_tv], axis = 0)
        test_data['TARGET_A'] = target_A_test
        #
        tv_data['TARGET_B'] = torch.concat([target_B_tv, target_A_tv], axis = 0)
        test_data['TARGET_B'] = target_B_test
        #
        tv_data['cell_BASAL'] = torch.concat((cell_basal_tv, cell_basal_tv), axis=0)
        test_data['cell_BASAL'] = cell_basal_test
        ##
        tv_data['cell'] = torch.concat((cell_tv, cell_tv), axis=0)
        test_data['cell'] = cell_test
        #            
        tv_data['y'] = torch.concat((syn_tv, syn_tv), axis=0)
        test_data['y'] = syn_test
        #
        print(tv_data['drug1_feat'].shape, flush=True)
        print(test_data['drug1_feat'].shape, flush=True)
        return tv_data, test_data


class DATASET_GCN_W_FT(Dataset):
        def __init__(self, gcn_drug1_F, gcn_drug2_F, gcn_drug1_ADJ, gcn_drug2_ADJ,
        gcn_gene_A, gcn_gene_B, target_A, target_B, cell_basal, gcn_adj, gcn_adj_weight,
        cell_info, syn_ans ):
                self.gcn_drug1_F = gcn_drug1_F
                self.gcn_drug2_F = gcn_drug2_F
                self.gcn_drug1_ADJ = gcn_drug1_ADJ
                self.gcn_drug2_ADJ = gcn_drug2_ADJ
                self.gcn_gene_A = gcn_gene_A
                self.gcn_gene_B = gcn_gene_B
                self.target_A = target_A
                self.target_B = target_B
                self.cell_basal = cell_basal
                self.gcn_adj = gcn_adj
                self.gcn_adj_weight = gcn_adj_weight
                self.syn_ans = syn_ans
                self.cell_info = cell_info
                #
        #
        def __len__(self):
                return len(self.gcn_drug1_F)
                        #
        def __getitem__(self, index):
                adj_re_A = self.gcn_drug1_ADJ[index].long().to_sparse().indices()
                adj_re_B = self.gcn_drug2_ADJ[index].long().to_sparse().indices()
                #
                FEAT_A = torch.Tensor(np.array([ self.gcn_gene_A[index].squeeze().tolist() , self.target_A[index].tolist(), self.cell_basal[index].tolist()]).T)
                FEAT_B = torch.Tensor(np.array([ self.gcn_gene_B[index].squeeze().tolist() , self.target_B[index].tolist(), self.cell_basal[index].tolist()]).T)
                #
                return self.gcn_drug1_F[index], self.gcn_drug2_F[index],adj_re_A, adj_re_B, FEAT_A, FEAT_B, self.gcn_adj, self.gcn_adj_weight , self.cell_info[index], self.syn_ans[index]


def graph_collate_fn(batch):
        drug1_f_list = []
        drug2_f_list = []
        drug1_adj_list = []
        drug2_adj_list = []
        expA_list = []
        expB_list = []
        exp_adj_list = []
        exp_adj_w_list = []
        y_list = []
        cell_list = []
        EXP_num_nodes_seen = 0
        DRUG_1_num_nodes_seen = 0
        DRUG_2_num_nodes_seen = 0
        #
        for drug1_f, drug2_f, drug1_adj, drug2_adj, expA, expB, exp_adj, exp_adj_w, cell, y in batch :
                drug1_f_list.append(drug1_f)
                drug2_f_list.append(drug2_f)
                drug1_adj_list.append(drug1_adj+DRUG_1_num_nodes_seen)
                drug2_adj_list.append(drug2_adj+DRUG_2_num_nodes_seen)
                expA_list.append(expA)
                expB_list.append(expB)
                exp_adj_list.append(exp_adj+EXP_num_nodes_seen)
                exp_adj_w_list.append(exp_adj_w)
                y_list.append(torch.Tensor(y))
                cell_list.append(torch.Tensor(cell))
                EXP_num_nodes_seen += expA.shape[0]
                DRUG_1_num_nodes_seen += drug1_f.shape[0]
                DRUG_2_num_nodes_seen += drug2_f.shape[0]
        #
        drug1_f_new = torch.cat(drug1_f_list, 0)
        drug2_f_new = torch.cat(drug2_f_list, 0)
        drug1_adj_new = torch.cat(drug1_adj_list, 1)
        drug2_adj_new = torch.cat(drug2_adj_list, 1)
        expA_new = torch.cat(expA_list, 0)
        expB_new = torch.cat(expB_list, 0)
        exp_adj_new = torch.cat(exp_adj_list, 1)
        exp_adj_w_new = torch.cat(exp_adj_w_list, 1)
        y_new = torch.stack(y_list, 0)
        cell_new = torch.stack(cell_list, 0)
        return drug1_f_new, drug2_f_new, drug1_adj_new, drug2_adj_new, expA_new, expB_new, exp_adj_new, exp_adj_w_new, cell_new, y_new



def weighted_mse_loss(input, target, weight):
        return (weight * (input - target) ** 2).mean()


def result_pearson(y, pred):
        pear = stats.pearsonr(y, pred)
        pear_value = pear[0]
        pear_p_val = pear[1]
        print("Pearson correlation is {} and related p_value is {}".format(pear_value, pear_p_val), flush=True)


def result_spearman(y, pred):
        spear = stats.spearmanr(y, pred)
        spear_value = spear[0]
        spear_p_val = spear[1]
        print("Spearman correlation is {} and related p_value is {}".format(spear_value, spear_p_val), flush=True)



def plot_loss(train_loss, valid_loss, path, plotname):
        fig = plt.figure(figsize=(10,8))
        plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')
        plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')
        plt.xlabel('epochs')
        plt.ylabel('loss')
        plt.ylim(0, math.ceil(max(train_loss+valid_loss))) # 일정한 scale
        plt.xlim(0, len(train_loss)+1) # 일정한 scale
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        fig.savefig('{}/{}.loss_plot.png'.format(path, plotname), bbox_inches = 'tight')


seed = 42
random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)



# gcn_drug1_F, gcn_drug2_F, gcn_drug1_ADJ, gcn_drug2_ADJ, gcn_exp_A, gcn_exp_B, gcn_tgt_A, gcn_tgt_B, gcn_adj, gcn_adj_weight, syn_ans, cell_info
norm = 'tanh_norm'

# CV_0
train_data_0, test_data_0 = prepare_data_GCN(0, A_B_C_S_SET_SM, MY_chem_A_feat_RE2, MY_chem_B_feat_RE2, MY_chem_A_adj_RE2, MY_chem_B_adj_RE2,
MY_g_EXP_A_RE2, MY_g_EXP_B_RE2, MY_Target_A2, MY_Target_B2, MY_CellBase_RE2,
cell_one_hot, MY_syn_RE2, norm)

# CV_1
train_data_1, test_data_1 = prepare_data_GCN(1, A_B_C_S_SET_SM, MY_chem_A_feat_RE2, MY_chem_B_feat_RE2, MY_chem_A_adj_RE2, MY_chem_B_adj_RE2,
MY_g_EXP_A_RE2, MY_g_EXP_B_RE2, MY_Target_A2, MY_Target_B2, MY_CellBase_RE2,
cell_one_hot, MY_syn_RE2, norm)

# CV_2
train_data_2, test_data_2 = prepare_data_GCN(2, A_B_C_S_SET_SM, MY_chem_A_feat_RE2, MY_chem_B_feat_RE2, MY_chem_A_adj_RE2, MY_chem_B_adj_RE2,
MY_g_EXP_A_RE2, MY_g_EXP_B_RE2, MY_Target_A2, MY_Target_B2, MY_CellBase_RE2,
cell_one_hot, MY_syn_RE2, norm)

# CV_3
train_data_3, test_data_3 = prepare_data_GCN(3, A_B_C_S_SET_SM, MY_chem_A_feat_RE2, MY_chem_B_feat_RE2, MY_chem_A_adj_RE2, MY_chem_B_adj_RE2,
MY_g_EXP_A_RE2, MY_g_EXP_B_RE2, MY_Target_A2, MY_Target_B2, MY_CellBase_RE2,
cell_one_hot, MY_syn_RE2, norm)

# CV_4
train_data_4, test_data_4 = prepare_data_GCN(4, A_B_C_S_SET_SM, MY_chem_A_feat_RE2, MY_chem_B_feat_RE2, MY_chem_A_adj_RE2, MY_chem_B_adj_RE2,
MY_g_EXP_A_RE2, MY_g_EXP_B_RE2, MY_Target_A2, MY_Target_B2, MY_CellBase_RE2,
cell_one_hot, MY_syn_RE2, norm)

# WEIGHT 
def get_loss_weight(CV) :
        train_data = globals()['train_data_'+str(CV)]
        ys = train_data['y'].squeeze().tolist()
        min_s = np.amin(ys)
        loss_weight = np.log(train_data['y'] - min_s + np.e)
        return loss_weight


JY_IDX_WEIGHT_T = torch.Tensor(JY_IDX_WEIGHT).view(1,-1)





# DATA check  
def make_merged_data(CV) :
        train_data = globals()['train_data_'+str(CV)]
        test_data = globals()['test_data_'+str(CV)]
        #
        T_train = DATASET_GCN_W_FT(
                torch.Tensor(train_data['drug1_feat']), torch.Tensor(train_data['drug2_feat']),
                torch.Tensor(train_data['drug1_adj']), torch.Tensor(train_data['drug2_adj']),
                torch.Tensor(train_data['GENE_A']), torch.Tensor(train_data['GENE_B']),
                torch.Tensor(train_data['TARGET_A']), torch.Tensor(train_data['TARGET_B']), torch.Tensor(train_data['cell_BASAL']),
                JY_ADJ_IDX, JY_IDX_WEIGHT_T,
                train_data['cell'].float(),
                torch.Tensor(train_data['y'])
                )
        #
        #       
        T_test = DATASET_GCN_W_FT(
                torch.Tensor(test_data['drug1_feat']), torch.Tensor(test_data['drug2_feat']),
                torch.Tensor(test_data['drug1_adj']), torch.Tensor(test_data['drug2_adj']),
                torch.Tensor(test_data['GENE_A']), torch.Tensor(test_data['GENE_B']),
                torch.Tensor(test_data['TARGET_A']), torch.Tensor(test_data['TARGET_B']), torch.Tensor(test_data['cell_BASAL']),
                JY_ADJ_IDX, JY_IDX_WEIGHT_T,
                test_data['cell'].float(),
                torch.Tensor(test_data['y'])
                )
        #
        return T_train, T_test




# CV 0 
T_train_0, T_test_0 = make_merged_data(0)
RAY_test_0 = ray.put(T_test_0)


# CV 1
T_train_1, T_test_1 = make_merged_data(1)
RAY_test_1 = ray.put(T_test_1)


# CV 2 
T_train_2, T_test_2 = make_merged_data(2)
RAY_test_2 = ray.put(T_test_2)


# CV 3
T_train_3, T_test_3 = make_merged_data(3)
RAY_test_3 = ray.put(T_test_3)


# CV 4
T_train_4, T_test_4 = make_merged_data(4)
RAY_test_4 = ray.put(T_test_4)





def inner_val( LOADER_DICT, THIS_MODEL , use_cuda = False) :
        THIS_MODEL.eval()
        #
        running_loss = 0
        last_loss = 0
        #
        ans_list = []
        pred_list = []
        vec1_concat = torch.empty(size=(0,16))##############
        vec2_concat = torch.empty(size=(0,16))
        with torch.no_grad() :
                for batch_idx_v, (drug1_f, drug2_f, drug1_a, drug2_a, expA, expB, adj, adj_w, cell, y) in enumerate(LOADER_DICT['test']) :
                        expA = expA.view(-1,3)#### 다른점 
                        expB = expB.view(-1,3)#### 다른점 
                        adj_w = adj_w.squeeze()
                        # move to GPU
                        if use_cuda:
                                drug1_f, drug2_f, drug1_a, drug2_a, expA, expB, adj, adj_w, y, cell = drug1_f.cuda(), drug2_f.cuda(), drug1_a.cuda(), drug2_a.cuda(), expA.cuda(), expB.cuda(), adj.cuda(), adj_w.cuda(), y.cuda(), cell.cuda()
                        ## update the average validation loss
                        output, vec1, vec2 = THIS_MODEL(drug1_f, drug2_f, drug1_a, drug2_a, expA, expB, adj, adj_w, cell, y)
                        MSE = torch.nn.MSELoss()
                        loss = MSE(output, y) # train 이 아니라서 weight 안넣어줌. 그냥 nn.MSE 넣어주기 
                        # update average validation loss 
                        running_loss = running_loss + loss.item()
                        pred_list = pred_list + output.squeeze().tolist()
                        ans_list = ans_list + y.squeeze().tolist()
                        vec1_concat = torch.concat([vec1_concat, vec1])
                        vec2_concat = torch.concat([vec2_concat, vec2])
                #
        last_loss = running_loss / (batch_idx_v+1)
        val_sc, _ = stats.spearmanr(pred_list, ans_list)
        val_pc, _ = stats.pearsonr(pred_list, ans_list)
        return last_loss, val_pc, val_sc, THIS_MODEL, ans_list, pred_list, vec1_concat, vec2_concat




class MY_expGCN_parallel_model(torch.nn.Module):
	def __init__(self, G_layer_chem, G_indim_chem, G_hiddim_chem, 
	G_layer_exp, G_indim_exp, G_hiddim_exp, 
	layers_1, layers_2, layers_3, 
	out_dim, inDrop, drop):
		super(MY_expGCN_parallel_model, self).__init__()
		self.G_layer_chem = G_layer_chem
		self.G_indim_chem = G_indim_chem
		self.G_hiddim_chem = G_hiddim_chem
		self.G_layer_exp = G_layer_exp
		self.G_indim_exp = G_indim_exp
		self.G_hiddim_exp = G_hiddim_exp
		self.G_Common_dim = min([G_hiddim_chem,G_hiddim_exp])
		self.layers_1 = [int(a) for a in layers_1]
		self.layers_2 = [int(a) for a in layers_2]
		self.layers_3 = [int(a) for a in layers_3]
		self.out_dim = out_dim
		self.inDrop = inDrop
		self.drop = drop
		self.tanh = torch.nn.Tanh()
		self.pool = pyg_nn.global_mean_pool
		#
		self.G_convs_1_chem = torch.nn.ModuleList([pyg_nn.GCNConv(self.G_indim_chem, self.G_hiddim_chem)])
		self.G_convs_1_chem.extend([pyg_nn.GCNConv(self.G_hiddim_chem, self.G_hiddim_chem) for i in range(self.G_layer_chem-2)])
		self.G_convs_1_chem.extend([pyg_nn.GCNConv(self.G_hiddim_chem, self.G_Common_dim)])
		self.G_bns_1_chem = torch.nn.ModuleList([torch.nn.BatchNorm1d(self.G_hiddim_chem) for i in range(self.G_layer_chem-1)])
		##
		self.G_convs_1_exp = torch.nn.ModuleList([pyg_nn.GCNConv(self.G_indim_exp, self.G_hiddim_exp)])
		self.G_convs_1_exp.extend([pyg_nn.GCNConv(self.G_hiddim_exp, self.G_hiddim_exp) for i in range(self.G_layer_exp-2)])
		self.G_convs_1_exp.extend([pyg_nn.GCNConv(self.G_hiddim_exp, self.G_Common_dim)])
		self.G_bns_1_exp = torch.nn.ModuleList([torch.nn.BatchNorm1d(self.G_hiddim_exp) for i in range(self.G_layer_exp-1)])
		##
		self.Convs_1 = torch.nn.ModuleList([torch.nn.Linear(self.G_Common_dim+self.G_Common_dim, self.layers_1[0] )])
		self.Convs_1.extend([torch.nn.Linear(self.layers_1[a], self.layers_1[a+1]) for a in range(len(self.layers_1)-1)])
		##
		self.SNPs = torch.nn.ModuleList([torch.nn.Linear(self.layers_1[-1]+self.layers_2[-1], self.layers_3[0] )])
		self.SNPs.extend([torch.nn.Linear(self.layers_3[a], self.layers_3[a+1]) for a in range(len(self.layers_3)-1)])
		self.SNPs.extend([torch.nn.Linear(self.layers_3[-1], self.out_dim)])
		#
		self.reset_parameters()
	#
	def reset_parameters(self):
		for conv in self.G_convs_1_chem :
			conv.reset_parameters()
		for bns in self.G_bns_1_chem :
			bns.reset_parameters()
		for conv in self.G_convs_1_exp :
			conv.reset_parameters()
		for bns in self.G_bns_1_exp :
			bns.reset_parameters()
		for conv in self.Convs_1 :
			conv.reset_parameters()
		for conv in self.SNPs:
			conv.reset_parameters()
	#
	def calc_batch_label (self, syn, feat) :
		batchnum = syn.shape[0]
		nodenum = feat.shape[0]/batchnum
		Num = [a for a in range(batchnum)]
		Rep = np.repeat(Num, nodenum)
		batch_labels = torch.Tensor(Rep).long()
		if torch.cuda.is_available():
			batch_labels = batch_labels.cuda()
		return batch_labels
	#
	def forward(self, Drug1_F, Drug2_F, Drug1_ADJ, Drug2_ADJ, EXP1, EXP2, EXP_ADJ, EXP_ADJ_WGT, cell, syn ):
		Drug_batch_label = self.calc_batch_label(syn, Drug1_F)
		Exp_batch_label = self.calc_batch_label(syn, EXP1)
		#
		for G_1_C in range(len(self.G_convs_1_chem)):
			if G_1_C == len(self.G_convs_1_chem)-1 :
				Drug1_F = self.G_convs_1_chem[G_1_C](x=Drug1_F, edge_index=Drug1_ADJ)
				Drug1_F = F.dropout(Drug1_F, p=self.inDrop, training=self.training)
				Drug1_F = self.pool(Drug1_F, Drug_batch_label )
				Drug1_F = self.tanh(Drug1_F)
				G_1_C_out = Drug1_F
			else :
				Drug1_F = self.G_convs_1_chem[G_1_C](x=Drug1_F, edge_index=Drug1_ADJ)
				Drug1_F = self.G_bns_1_chem[G_1_C](Drug1_F)
				Drug1_F = F.elu(Drug1_F)
		#
		for G_2_C in range(len(self.G_convs_1_chem)):
			if G_2_C == len(self.G_convs_1_chem)-1 :
				Drug2_F = self.G_convs_1_chem[G_2_C](x=Drug2_F, edge_index=Drug2_ADJ)
				Drug2_F = F.dropout(Drug2_F, p=self.inDrop, training=self.training)
				Drug2_F = self.pool(Drug2_F, Drug_batch_label )
				Drug2_F = self.tanh(Drug2_F)
				G_2_C_out = Drug2_F
			else :
				Drug2_F = self.G_convs_1_chem[G_2_C](x=Drug2_F, edge_index=Drug2_ADJ)
				Drug2_F = self.G_bns_1_chem[G_2_C](Drug2_F)
				Drug2_F = F.elu(Drug2_F)
		#
		for G_1_E in range(len(self.G_convs_1_exp)):
			if G_1_E == len(self.G_convs_1_exp)-1 :
				EXP1 = self.G_convs_1_exp[G_1_E](x=EXP1, edge_index=EXP_ADJ, edge_weight= EXP_ADJ_WGT)
				EXP1 = F.dropout(EXP1, p=self.inDrop, training=self.training)
				EXP1 = self.pool(EXP1, Exp_batch_label )
				EXP1 = self.tanh(EXP1)
				G_1_E_out = EXP1
			else :
				EXP1 = self.G_convs_1_exp[G_1_E](x=EXP1, edge_index=EXP_ADJ, edge_weight= EXP_ADJ_WGT)
				EXP1 = self.G_bns_1_exp[G_1_E](EXP1)
				EXP1 = F.elu(EXP1)
		#
		for G_2_E in range(len(self.G_convs_1_exp)):
			if G_2_E == len(self.G_convs_1_exp)-1 :
				EXP2 = self.G_convs_1_exp[G_2_E](x=EXP2, edge_index=EXP_ADJ, edge_weight= EXP_ADJ_WGT)
				EXP2 = F.dropout(EXP2, p=self.inDrop, training=self.training)
				EXP2 = self.pool(EXP2, Exp_batch_label )
				EXP2 = self.tanh(EXP2)
				G_2_E_out = EXP2
			else :
				EXP2 = self.G_convs_1_exp[G_2_E](x=EXP2, edge_index=EXP_ADJ, edge_weight= EXP_ADJ_WGT)
				EXP2 = self.G_bns_1_exp[G_2_E](EXP2)
				EXP2 = F.elu(EXP2)
		#
		input_drug1 = torch.concat( (G_1_C_out, G_1_E_out), 1 ) # normalization 추가 해야할것 같은데 
		input_drug2 = torch.concat( (G_2_C_out, G_2_E_out), 1 )
		#
		for L1 in range(len(self.Convs_1)):
			if L1 != len(self.Convs_1)-1 :
				input_drug1 = self.Convs_1[L1](input_drug1)
				input_drug1 = F.dropout(input_drug1, p=self.inDrop, training = self.training)
				input_drug1 = F.elu(input_drug1)
			else :
				input_drug1 = self.Convs_1[L1](input_drug1)
		#
		for L2 in range(len(self.Convs_1)):
			if L2 != len(self.Convs_1)-1 :
				input_drug2 = self.Convs_1[L2](input_drug2)
				input_drug2 = F.dropout(input_drug2, p=self.inDrop, training = self.training)
				input_drug2 = F.elu(input_drug2)
			else :
				input_drug2 = self.Convs_1[L2](input_drug2)
		#
		X = torch.cat(( input_drug1, input_drug2 ), 1)
		for L3 in range(len(self.SNPs)):
			if L3 != len(self.SNPs)-1 :
				X = self.SNPs[L3](X)
				X = F.dropout(X, p=self.drop, training = self.training)
				X = F.elu(X)
			else :
				X = self.SNPs[L3](X)
		return X, G_1_E_out, G_2_E_out



config/G_chem_hdim                                                       32
config/G_chem_layer                                                       2
config/G_exp_hdim                                                        16
config/G_exp_layer                                                        3
config/batch_size                                                       512
config/dropout_1                                                        0.1
config/dropout_2                                                        0.1
config/dsn_layer                                                 256-128-64
config/epoch                                                            500
config/lr                                                             0.001
config/n_workers                                                          8
config/snp_layer                                                    32-16-8


config = {'Unnamed: 0': 41, 'AV_T_LS': 539.8539381117755, 'AV_T_PC': 0.717534614316981, 'AV_T_SC': 0.6311907307890909, 'AV_V_LS': 117.32033359031963, 'AV_V_PC': 0.6949156368709531, 'AV_V_SC': 0.629205867704111, 'time_this_iter_s': 144.44655442237854, 'should_checkpoint': True, 'done': True, 'training_iteration': 500, 'trial_id': '1cf5052a', 'experiment_id': '2558c76710704eff916caebbd82f9c6d', 'date': '2023-06-22_15-53-26', 'timestamp': 1687416806, 'time_total_s': 89881.6727283001, 'pid': 63052, 'hostname': 'bdata11', 'node_ip': '172.21.1.21', 'time_since_restore': 89881.6727283001, 'timesteps_since_restore': 0, 'iterations_since_restore': 500, 'warmup_time': 0.0056948661804199, 'config/G_chem_hdim': 32, 'config/G_chem_layer': 2, 'config/G_exp_hdim': 16, 'config/G_exp_layer': 3, 'config/batch_size': 512, 'config/dropout_1': 0.1, 'config/dropout_2': 0.1, 'config/dsn_layer': '256-128-64', 'config/epoch': 500, 'config/lr': 0.001, 'config/n_workers': 8, 'config/snp_layer': '32-16-8', 'logdir': '/home01/k040a01/ray_results/PRJ02.23.06.20.M3V6.WORK_202.349.MIS2/RAY_MY_train_1cf5052a_42_G_chem_hdim=32,G_chem_layer=2,G_exp_hdim=16,G_exp_layer=3,batch_size=512,dropout_1=0.1000,dropout_2=0.100_2023-06-21_14-55-20'}

n_epochs = 1000
use_cuda = False  #  #  #  #  #  #  # True
#
dsn_layers = [int(a) for a in config["config/dsn_layer"].split('-') ]
snp_layers = [int(a) for a in config["config/snp_layer"].split('-') ]
inDrop = config["config/dropout_1"]
Drop = config["config/dropout_2"]
#
RAY_test_list = [RAY_test_0 ,RAY_test_1 ,RAY_test_2 ,RAY_test_3 ,RAY_test_4 ]
#
#



                                                                                                                                                                                                        # stopper 테스트 
                                                                                                                                                                                                        CV_NUM = 0 
                                                                                                                                                                                                        CV_0_test = ray.get(RAY_test_list[CV_NUM])
                                                                                                                                                                                                        CV_0_loaders = {'test' : torch.utils.data.DataLoader(CV_0_test, batch_size = config["config/batch_size"], collate_fn = graph_collate_fn, shuffle =False)}
                                                                                                                                                                                                        CV_0_MODEL = MY_expGCN_parallel_model(
                                                                                                                                                                                                                        config["config/G_chem_layer"], 64 , config["config/G_chem_hdim"],      # G_layer_chem, G_indim_chem, G_hiddim_chem, 
                                                                                                                                                                                                                        config["config/G_exp_layer"], 3 , config["config/G_exp_hdim"],      # G_layer_exp, G_indim_exp, G_hiddim_exp, 
                                                                                                                                                                                                                        dsn_layers, dsn_layers, snp_layers,      # drug 1 layers, drug 2 layers, merged layer, 
                                                                                                                                                                                                                        1,      # cell_dim ,out_dim,
                                                                                                                                                                                                                        inDrop, Drop      # inDrop, drop
                                                                                                                                                                                                                        )

                                                                                                                                                                                                        state_dict = torch.load(os.path.join('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/217_1', 'CV_{}'.format(CV_NUM)), map_location=torch.device('cpu'))

                                                                                                                                                                                                        if type(state_dict) == tuple:
                                                                                                                                                                                                                CV_0_MODEL.load_state_dict(state_dict[0])
                                                                                                                                                                                                        else : 
                                                                                                                                                                                                                CV_0_MODEL.load_state_dict(state_dict)	#


                                                                                                                                                                                                        지금 하나 확인해봐야하는거 : 내가 tsne 를 그린 방법이 좀 틀린것 같음. 
                                                                                                                                                                                                        왜냐면 cell line 에서 구한 모든 drug-drug embedding vector 를 가지고 그려야하는건데, 
                                                                                                                                                                                                        지금 나는 내가 새로 구한 synergy score 만 가지고 진행했음 .
                                                                                                                                                                                                        synergy score distance 는 원래 answer 값 가지고 진행해야하는것 같음 

                                                                                                                                                                                                        THIS_MODEL.G_convs_1_exp.register_forward_hook(get_activation('G_convs_1_exp'))

                                                                                                                                                                                                        CV_0_MODEL.eval()
                                                                                                                                                                                                                #
                                                                                                                                                                                                        running_loss = 0
                                                                                                                                                                                                        last_loss = 0
                                                                                                                                                                                                        #
                                                                                                                                                                                                        ans_list = []
                                                                                                                                                                                                        pred_list = []



                                                                                                                                                                                                        with torch.no_grad() :
                                                                                                                                                                                                                for batch_idx_v, (drug1_f, drug2_f, drug1_a, drug2_a, expA, expB, adj, adj_w, cell, y) in enumerate(CV_0_loaders['test']) :
                                                                                                                                                                                                                        expA = expA.view(-1,3)#### 다른점 
                                                                                                                                                                                                                        expB = expB.view(-1,3)#### 다른점 
                                                                                                                                                                                                                        adj_w = adj_w.squeeze()
                                                                                                                                                                                                                        # move to GPU
                                                                                                                                                                                                                        if use_cuda:
                                                                                                                                                                                                                                drug1_f, drug2_f, drug1_a, drug2_a, expA, expB, adj, adj_w, y, cell = drug1_f.cuda(), drug2_f.cuda(), drug1_a.cuda(), drug2_a.cuda(), expA.cuda(), expB.cuda(), adj.cuda(), adj_w.cuda(), y.cuda(), cell.cuda()
                                                                                                                                                                                                                        ## update the average validation loss
                                                                                                                                                                                                                        output, vec1, vec2 = CV_0_MODEL(drug1_f, drug2_f, drug1_a, drug2_a, expA, expB, adj, adj_w, cell, y)
                                                                                                                                                                                                                        MSE = torch.nn.MSELoss()
                                                                                                                                                                                                                        loss = MSE(output, y) # train 이 아니라서 weight 안넣어줌. 그냥 nn.MSE 넣어주기 
                                                                                                                                                                                                                        # update average validation loss 
                                                                                                                                                                                                                        running_loss = running_loss + loss.item()
                                                                                                                                                                                                                        pred_list = pred_list + output.squeeze().tolist()
                                                                                                                                                                                                                        ans_list = ans_list + y.squeeze().tolist()
                                                                                                                                                                                                                #









def cv_result(CV_NUM):
    CV_0_test = ray.get(RAY_test_list[CV_NUM])
    #
    CV_0_loaders = {'test' : torch.utils.data.DataLoader(CV_0_test, batch_size = config["config/batch_size"], collate_fn = graph_collate_fn, shuffle =False)}
    #  
    CV_0_MODEL = MY_expGCN_parallel_model(
                    config["config/G_chem_layer"], CV_0_test.gcn_drug1_F.shape[-1] , config["config/G_chem_hdim"],      # G_layer_chem, G_indim_chem, G_hiddim_chem, 
                    config["config/G_exp_layer"], 3 , config["config/G_exp_hdim"],      # G_layer_exp, G_indim_exp, G_hiddim_exp, 
                    dsn_layers, dsn_layers, snp_layers,      # drug 1 layers, drug 2 layers, merged layer, 
                    1,      # cell_dim ,out_dim,
                    inDrop, Drop      # inDrop, drop
                    )
    #
    state_dict = torch.load(os.path.join('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/217_1', 'CV_{}'.format(CV_NUM)), map_location=torch.device('cpu'))
    #
    if type(state_dict) == tuple:
        CV_0_MODEL.load_state_dict(state_dict[0])
    else : 
        CV_0_MODEL.load_state_dict(state_dict)	#
    #
    cv_0_v_loss, cv_0_v_pc, cv_0_v_sc, CV_0_MODEL, ans_list_0, pred_list_0, vec1, vec2  = inner_val(CV_0_loaders, CV_0_MODEL, False)
    return ans_list_0, pred_list_0, vec1, vec2 


ans_list_0, pred_list_0, A_vec_0, B_vec_0 = cv_result(0)
ans_list_1, pred_list_1, A_vec_1, B_vec_1 = cv_result(1)
ans_list_2, pred_list_2, A_vec_2, B_vec_2 = cv_result(2)
ans_list_3, pred_list_3, A_vec_3, B_vec_3 = cv_result(3)
ans_list_4, pred_list_4, A_vec_4, B_vec_4 = cv_result(4)


ABCS_test_0 = A_B_C_S_SET_SM[A_B_C_S_SET_SM.SM_C_CHECK.isin(CV_ND_INDS['CV0_test'])]
ABCS_test_1 = A_B_C_S_SET_SM[A_B_C_S_SET_SM.SM_C_CHECK.isin(CV_ND_INDS['CV1_test'])]
ABCS_test_2 = A_B_C_S_SET_SM[A_B_C_S_SET_SM.SM_C_CHECK.isin(CV_ND_INDS['CV2_test'])]
ABCS_test_3 = A_B_C_S_SET_SM[A_B_C_S_SET_SM.SM_C_CHECK.isin(CV_ND_INDS['CV3_test'])]
ABCS_test_4 = A_B_C_S_SET_SM[A_B_C_S_SET_SM.SM_C_CHECK.isin(CV_ND_INDS['CV4_test'])]

ABCS_test_0['ans'] = ans_list_0 ; ABCS_test_0['pred'] = pred_list_0
ABCS_test_1['ans'] = ans_list_1 ; ABCS_test_1['pred'] = pred_list_1
ABCS_test_2['ans'] = ans_list_2 ; ABCS_test_2['pred'] = pred_list_2
ABCS_test_3['ans'] = ans_list_3 ; ABCS_test_3['pred'] = pred_list_3
ABCS_test_4['ans'] = ans_list_4 ; ABCS_test_4['pred'] = pred_list_4

ABCS_test_all = pd.concat([ABCS_test_0, ABCS_test_1, ABCS_test_2, ABCS_test_3, ABCS_test_4])
ABCS_test_all = ABCS_test_all.reset_index(drop = True)


# vec check 
A_vec_all = torch.concat([A_vec_0, A_vec_1, A_vec_2, A_vec_3, A_vec_4])
B_vec_all = torch.concat([B_vec_0, B_vec_1, B_vec_2, B_vec_3, B_vec_4])
vec_all = torch.concat([A_vec_all, B_vec_all], axis =1)


all_cells = list(np.unique(ABCS_test_all.CELL))

cell_specific_vec = []

# cid_cid_list = []

for cell_name in all_cells : 
        cell_tmp = ABCS_test_all[ABCS_test_all.CELL==cell_name]
        cell_tmp = cell_tmp.sort_values('CID_CID')
        # cid_cid_list.append(list(cell_tmp['CID_CID']))
        cell_indd = list(cell_tmp.index)
        cell_vec = vec_all[cell_indd].view(1,-1).squeeze().tolist()
        cell_specific_vec.append(cell_vec)


cell_specific_vec_np = np.array(cell_specific_vec)






# 일단 pred synergy 이용한 점수별 거리 확인 

from sklearn.datasets import load_digits
from sklearn.manifold import TSNE



ABCS_test_all['tissue'] = ABCS_test_all['CELL'].apply(lambda x : '_'.join(x.split('_')[1:]))

ABCS_test_result_tsne = ABCS_test_all[['CID_CID','CELL','tissue', 'pred']]
cell_list = list(set(ABCS_test_result_tsne.CELL))
cell_list.sort()

test_1 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == 'A375_SKIN']
test_2 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == 'A2780_OVARY']
common_n = len(set(test_1.CID_CID) & set(test_2.CID_CID))


'148177___135398510'
test_1[test_1.CID_CID=='148177___135398510']['pred'].item()
test_2[test_2.CID_CID=='148177___135398510']['pred'].item()


cell_array = pd.DataFrame(columns = cell_list, index = cell_list)

for cell_1 in cell_list : 
	cell_1
	for cell_2 in cell_list : 
		ABCS_res_cell_1 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == cell_1]
		ABCS_res_cell_2 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == cell_2]
		common_n = list(set(ABCS_res_cell_1.CID_CID) & set(ABCS_res_cell_2.CID_CID))
		print(len(common_n))
		common_n.sort()
		std_list = []
		for cc in common_n : 
			test_1 = ABCS_res_cell_1[ABCS_res_cell_1.CID_CID==cc]['pred'].item()
			test_2 = ABCS_res_cell_2[ABCS_res_cell_2.CID_CID==cc]['pred'].item()
			std_res = np.std([test_1, test_2])
			std_list.append(std_res)
		cell_cell_res = np.mean(std_list)
		cell_array.at[cell_1, cell_2] = cell_cell_res
	



# cell_array.to_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W203_349_MIS2/TSNE_oneil_array.csv', sep = '\t')
cell_array.to_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/TSNE_oneil_array1.csv', sep = '\t')
# cell_array = pd.read_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W203_349_MIS2/TSNE_oneil_array.csv', sep = '\t')
# 모든 오닐 cell 사용. 
# cell_array1 = pd.read_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/TSNE_oneil_array1.csv', sep = '\t')




# 이건 ans 로 하는 경우.. 생각해보니 answer 데이터 이용해서한 결과에 대해 우리 결과가 잘 따라가야하는거임...! 
ABCS_test_all['tissue'] = ABCS_test_all['CELL'].apply(lambda x : '_'.join(x.split('_')[1:]))

ABCS_test_result_tsne = ABCS_test_all[['CID_CID','CELL','tissue', 'ans']]
cell_list = list(set(ABCS_test_result_tsne.CELL))
cell_list.sort()

test_1 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == 'A375_SKIN']
test_2 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == 'A2780_OVARY']
common_n = len(set(test_1.CID_CID) & set(test_2.CID_CID))

cell_array = pd.DataFrame(columns = cell_list, index = cell_list)

for cell_1 in cell_list : 
	cell_1
	for cell_2 in cell_list : 
		ABCS_res_cell_1 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == cell_1]
		ABCS_res_cell_2 = ABCS_test_result_tsne[ABCS_test_result_tsne.CELL == cell_2]
		common_n = list(set(ABCS_res_cell_1.CID_CID) & set(ABCS_res_cell_2.CID_CID))
		print(len(common_n))
		common_n.sort()
		std_list = []
		for cc in common_n : 
			test_1 = ABCS_res_cell_1[ABCS_res_cell_1.CID_CID==cc]['ans'].item()
			test_2 = ABCS_res_cell_2[ABCS_res_cell_2.CID_CID==cc]['ans'].item()
			std_res = np.std([test_1, test_2])
			std_list.append(std_res)
		cell_cell_res = np.mean(std_list)
		cell_array.at[cell_1, cell_2] = cell_cell_res
	

cell_array.to_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/TSNE_oneil_array.0801.csv', sep = '\t')









cell_array2 = np.array(cell_array)
cell_array2[np.isnan(cell_array2)] = 0
# 안머깋는디 

# 이거 반복해줘야할듯 
new_df = []
for ind in range(len(cell_list)) : 
	cell_row = cell_array2[ind]
	new_row_ind = [a for a in range(len(cell_row)) if np.isnan(cell_row[a])]
	cell_row[new_row_ind] = 0.0
	new_df.append(cell_row)


new_df2 = np.array(new_df)

n_components = 2



# TSNE 모델의 인스턴스를 만듭니다.
# 이건 우리 중간 layer 쓰기 전 버전 
model = TSNE(n_components=n_components)
# data를 가지고 TSNE 모델을 훈련(적용) 합니다.
X_embedded = model.fit_transform(np.array(new_df2))

TSNE_DF = pd.DataFrame(X_embedded)
TSNE_DF.columns = ['comp1','comp2']

cell_check = list(cell_array.index)
TSNE_DF['cell_lines'] = cell_check

cell_tiss = ['_'.join(a.split('_')[1:]) for a in cell_check]
TSNE_DF['tissue'] = cell_tiss

cell_strip = [a.split('_')[0] for a in cell_check]
TSNE_DF['strip'] = cell_strip

TSNE_DF.to_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/TSNE_217_1.csv', index = False)


tissue_set = ['CENTRAL_NERVOUS_SYSTEM', 'LUNG', 'BREAST', 'BONE', 'OVARY', 'PROSTATE', 'HAEMATOPOIETIC_AND_LYMPHOID_TISSUE', 'LARGE_INTESTINE', 'SKIN', 'PLEURA', 'KIDNEY' ] # list(set(test_cell_df['tissue']))
# 여기서만 central 색깔 좀 여리게 바꿔줌 
color_set = ['#d95e92','#FF7514','#025669','#308446','#84C3BE','#D53032','#4ddcfd','#ffcd36','#ac8cff',"#0000ffff","#7bff68ff"] # "#1E1E1E"
color_dict = {a : color_set[tissue_set.index(a)] for a in tissue_set}


# 밥먹고 오면 그림 그려보기 ! 이게 필터링 한 데이터  
# palette = sns.color_palette("bright", 10)
fig = plt.figure(figsize=(12,8))
ax = sns.scatterplot(data = TSNE_DF, x = 'comp1', y = 'comp2', hue = 'tissue', legend='full', palette=color_dict, size = 'tissue', sizes=[150]*len(set(cell_tiss)))  # 
for i in range(TSNE_DF.shape[0]):
    plt.text(TSNE_DF.comp1[i]-5.0 , TSNE_DF.comp2[i]+3.5, TSNE_DF.strip[i], size = 8 )

plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))
ax.set_xlabel('TSNE 1', fontsize=10)
ax.set_ylabel('TSNE 2', fontsize=10)

plt.tight_layout()
path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W214_349_MIS2'

plotname = 'tsne_trial'
fig.savefig('{}/{}.png'.format(path, plotname), bbox_inches = 'tight')


# 217_1 데이터
fig = plt.figure(figsize=(12,8))
ax = sns.scatterplot(data = TSNE_DF, x = 'comp1', y = 'comp2', hue = 'tissue', legend='full', palette=color_dict, size = 'tissue', sizes=[150]*len(set(cell_tiss)))  # 
for i in range(TSNE_DF.shape[0]):
    plt.text(TSNE_DF.comp1[i]-7.0 , TSNE_DF.comp2[i]+4.5, TSNE_DF.strip[i], size = 8 )

plt.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0)) # 
ax.set_xlabel('TSNE 1', fontsize=10)
ax.set_ylabel('TSNE 2', fontsize=10)

plt.tight_layout()
#path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W214_349_MIS2'
path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2'

plotname = 'tsne_trial_1'
fig.savefig('{}/{}.png'.format(path, plotname), bbox_inches = 'tight')









# 다시 우리 중간 layer 쓰는 방법 
trial = 10

cell_specific_vec_np = np.array(cell_specific_vec)
n_components = 2

model = TSNE(n_components=n_components)
X_embedded = model.fit_transform(cell_specific_vec_np)

TSNE_DF = pd.DataFrame(X_embedded)
TSNE_DF.columns = ['comp1','comp2']

TSNE_DF['cell_lines'] = all_cells

cell_tiss = ['_'.join(a.split('_')[1:]) for a in all_cells]
TSNE_DF['tissue'] = cell_tiss

cell_strip = [a.split('_')[0] for a in all_cells]
TSNE_DF['strip'] = cell_strip

TSNE_DF.to_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/TSNE_217_1.modelvec{}.csv'.format(trial), index = False)
# TSNE_DF = pd.read_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/TSNE_217_1.modelvec4.csv')

tissue_set = ['CENTRAL_NERVOUS_SYSTEM', 'LUNG', 'BREAST', 'BONE', 'OVARY', 'PROSTATE', 'HAEMATOPOIETIC_AND_LYMPHOID_TISSUE', 'LARGE_INTESTINE', 'SKIN', 'PLEURA', 'KIDNEY' ] # list(set(test_cell_df['tissue']))
# 여기서만 central 색깔 좀 여리게 바꿔줌 
color_set = ['#d95e92','#FF7514','#025669','#308446','#84C3BE','#D53032','#4ddcfd','#ffcd36','#ac8cff',"#0000ffff","#7bff68ff"] # "#1E1E1E"
color_dict = {a : color_set[tissue_set.index(a)] for a in tissue_set}

fig = plt.figure(figsize=(12,8))
ax = sns.scatterplot(data = TSNE_DF, x = 'comp1', y = 'comp2', hue = 'tissue', legend='full', palette=color_dict, size = 'tissue', sizes=[150]*len(set(cell_tiss)))  # 
for i in range(TSNE_DF.shape[0]):
    plt.text(TSNE_DF.comp1[i]-7.0 , TSNE_DF.comp2[i]+4.5, TSNE_DF.strip[i], size = 8 )

plt.legend(loc='upper left',  fontsize = 10) # bbox_to_anchor=(-1.0, 1.0),
ax.set_xlabel('TSNE 1', fontsize=10)
ax.set_ylabel('TSNE 2', fontsize=10)

plt.tight_layout()
path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2'

# 그림 이쁜거 고르려고 노력중 
plotname = 'tsne_vec_1'
plotname = 'tsne_vec_2'
plotname = 'tsne_vec_{}'.format(trial)
fig.savefig('{}/{}.png'.format(path, plotname), bbox_inches = 'tight')

plotname = 'tsne_vec_{}'.format(trial)
fig.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')









import matplotlib.pyplot as plt

tissue_set = ['CENTRAL_NERVOUS_SYSTEM', 'LUNG', 'BREAST', 'BONE', 'OVARY', 'PROSTATE', 'HAEMATOPOIETIC_AND_LYMPHOID_TISSUE', 'LARGE_INTESTINE', 'SKIN', 'PLEURA', 'KIDNEY' ] # list(set(test_cell_df['tissue']))
# 여기서만 central 색깔 좀 여리게 바꿔줌 
color_set = ['#d95e92','#FF7514','#025669','#308446','#84C3BE','#D53032','#4ddcfd','#ffcd36','#ac8cff',"#0000ffff","#7bff68ff"] # "#1E1E1E"
color_dict = {a : color_set[tissue_set.index(a)] for a in tissue_set}


# correlation plot 그리기 
cell_array1 = pd.read_csv('/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/TSNE_oneil_array1.csv', sep = '\t')

corr = cell_array1.corr()

mask = np.triu(np.ones_like(corr, dtype=bool)) # Generate a mask for the upper triangle
f, ax = plt.subplots(figsize=(11, 9))
diverging_palette = sns.color_palette("coolwarm", 7)
diverging_palette = sns.diverging_palette(h_neg=-1, h_pos=1, s=85, l=25, n=5,
                                          sep=5, center='light', as_cmap=False)


cmap = plt.get_cmap('RdBu_r', 11)

sns.heatmap(corr, mask=mask, cmap=cmap, vmin = -1, vmax = 1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_1_corr'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')


# clustermap 시도  1

cmap = plt.get_cmap('RdBu_r', 11)

gg = sns.clustermap(
	corr, center=0, cmap=cmap, vmin=-1, vmax=1,
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'correlation', method = 'complete',
	dendrogram_ratio=0.2, yticklabels=False) 


path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_2_corr'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()



# clustermap 시도  1

corr_col = list(corr.index)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('RdBu_r', 11)

gg = sns.clustermap(
	corr, center=0, cmap=cmap, vmin=-1, vmax=1,
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'correlation', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 


path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_2_corr'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()




# clustermap 시도  1
cell_array_re = cell_array1.iloc[:,1:]
cell_array_re.index = list(cell_array_re.columns)


corr_col = list(cell_array_re.columns)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('PuBu', 30) # 

gg = sns.clustermap(
	cell_array_re, cmap=cmap, vmin=0, vmax=6, # center=0, c
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'correlation', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 


path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_3_dist'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()






# clustermap 시도  1

corr_col = list(corr.index)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('RdBu_r', 11)

gg = sns.clustermap(
	corr, center=0, cmap=cmap, vmin=-1, vmax=1,
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'euclidean', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 





path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_4_corr'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()



# clustermap 시도  1

corr_col = list(corr.index)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('RdBu_r', 11)

gg = sns.clustermap(
	corr, center=0, cmap=cmap, vmin=-1, vmax=1,
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'cosine', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 


path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_5_corr'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()




# answer 로 그린거 
# clustermap
corr_2 = cell_array.astype(float).corr()

corr_col = list(corr_2.index)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('RdBu_r', 11)

gg = sns.clustermap(
	corr_2, center=0, cmap=cmap, vmin=-1, vmax=1,
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'cosine', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 


path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_6_corr2'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()






# answer 로 그린거 
# clustermap
cell_array = cell_array1.iloc[:,1:]
corr_2 = cell_array.astype(float).corr()

corr_col = list(corr_2.index)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('RdBu_r', 11)

corr_2.columns = [a.split('_')[0] for a in corr_2.columns]
corr_2.index = [a.split('_')[0] for a in corr_2.index]

gg = sns.clustermap(
	corr_2, center=0, cmap=cmap, 
        vmin=-1, vmax=1,
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'euclidean', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 

gg.ax_heatmap.set_xticklabels(gg.ax_heatmap.get_xmajorticklabels(), fontsize = 16)
gg.ax_heatmap.set_xticklabels(gg.ax_heatmap.get_ymajorticklabels(), fontsize = 16)

path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_7_corr2'
plt.savefig('{}/{}.png'.format(path, plotname), format="png", bbox_inches = 'tight')
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()





# answer 로 그린거 
# clustermap
cell_array = cell_array1.iloc[:,1:]
corr_2 = cell_array.astype(float).corr()

corr_col = list(corr_2.index)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('RdBu_r', 11)

corr_2.columns = [a.split('_')[0] for a in corr_2.columns]
corr_2.index = [a.split('_')[0] for a in corr_2.index]

gg = sns.clustermap(
	corr_2, center=0, cmap=cmap, 
        vmin=-1, vmax=1,
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'correlation', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 

gg.ax_heatmap.set_xticklabels(gg.ax_heatmap.get_xmajorticklabels(), fontsize = 16)
gg.ax_heatmap.set_xticklabels(gg.ax_heatmap.get_ymajorticklabels(), fontsize = 16)

path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_9_corr2'
plt.savefig('{}/{}.png'.format(path, plotname), format="png", bbox_inches = 'tight')
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()




















# clustermap 시도  1
cell_array_re = cell_array1.iloc[:,1:]
cell_array_re.index = list(cell_array_re.columns)

corr_col = list(cell_array_re.columns)
tissue_list = ['_'.join(x.split('_')[1:]) for x in corr_col]
row_colors = [color_dict[tt] for tt in tissue_list]

cmap = plt.get_cmap('PuBu', 30) # 

cell_array_re.columns = [a.split('_')[0] for a in cell_array_re.columns]
cell_array_re.index = [a.split('_')[0] for a in cell_array_re.index]

gg = sns.clustermap(
	cell_array_re, cmap=cmap, vmin=0, vmax=6, # center=0, c
	figsize=(20,20),
	row_cluster=True, col_cluster = True, 
	metric = 'correlation', method = 'complete',
        row_colors = row_colors,
	dendrogram_ratio=0.2) 


gg.ax_heatmap.set_xticklabels(gg.ax_heatmap.get_xmajorticklabels(), fontsize = 16)
gg.ax_heatmap.set_xticklabels(gg.ax_heatmap.get_ymajorticklabels(), fontsize = 16)


path = '/st06/jiyeonH/11.TOX/DR_SPRING/trials/M3V6_W217_349_MIS2/'
plotname = 'corrplot_8_dist2'
plt.savefig('{}/{}.pdf'.format(path, plotname), format="pdf", bbox_inches = 'tight')
plt.close()



